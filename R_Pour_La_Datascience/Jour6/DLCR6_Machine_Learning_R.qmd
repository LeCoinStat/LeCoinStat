---
title: "DLCR6_Modèles_Machine_Learning"
format: html
editor: visual
---

# Régression logistique en R

```{r}
df <-  read.csv("/Users/natachanjongwayepnga/Documents/GitHub/LeCoinStat/R_Pour_La_Datascience/Jour6/titanic.csv")



```

# Preprocessing

```{r}
#install.packages("caret")
library(caret)
```

```{r}
summary(df)
# imputer les valeurs manquantes par le moyenne
df$Age[is.na(df$Age)] <- mean(df$Age, na.rm = T)
```

```{r}
str(df)
df$Survived <- as.factor(df$Survived)
df$Sex <- as.factor(df$Sex)
df$Pclass <- as.factor(df$Pclass)
```

# Diviser la base de données deux

La base d'apprentissage 70% de la base totale

La base test: 30%

```{r}
#install.packages(caret)
df <-df[, c(2,3,5,6,7,8,10)]
library(caret)
set.seed(123)# Assurer la reproductibilité de votre 
index <- createDataPartition(df$Survived,p=0.7, list=F)
```

```{r}
base_train <- df[index, ]
base_test <- df[-index,]

names(base_train)
```

```{r}
# autre option
index <- sample(1:nrow(df), 0.7*nrow(df))


```

# Regression logistique

```{r}
model_logistique <- glm(Survived ~ ., family = binomial, data = base_train)

model_logistique2 <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare, family = binomial, data = base_train)
```

```{r}
# Stocker le modèle
saveRDS(model_logistique, "/Users/natachanjongwayepnga/Documents/GitHub/LeCoinStat/R_Pour_La_Datascience/Jour7/model_logistique_final.rds")
```

```{r}
summary(model_logistique)
```

```{r}
anova(model_logistique, test = "Chisq")
```

```{r}

# Significativité globale du modèle
 G2 = model_logistique$null.deviance-model_logistique$deviance
 
  1-pchisq(G2,df=1)
```

## Prédiction sur une nouvelle base

```{r}
prediction <- predict(model_logistique, type = "response")

```

```{r}
# Package pour l'évaluation des modèles
#install.packages("pROC")
library(pROC)

prediction <- predict(model_logistique, newdata = base_test[,-1],type = "response")


```

```{r}
roc_obj <- roc(base_test$Survived, prediction, levels=c("0", "1"))
print(auc(roc_obj))
plot(roc_obj, main="Courbe ROC")
```

```{r}

roc_resultat <- roc(response = base_test$Survived, predictor = prediction)
auc_resultat <- auc(roc_resultat)
auc_resultat

```

## Prédiction base d'apprentissage

```{r}

prediction <- predict(model_logistique,type = "response")
prediction

roc_obj <- roc(base_train$Survived, prediction, levels=c("0", "1"))
print(auc(roc_obj))
plot(roc_obj, main="Courbe ROC")

roc_resultat <- roc(response = base_train$Survived, predictor = prediction)
auc_resultat <- auc(roc_resultat)
auc_resultat
```

# Forêts aléatoires

```{r}
#install.packages("randomForest")
library(randomForest)
```

```{r}
model_rf <- randomForest(Survived ~ ., data=base_train, importance=TRUE,
                        ntree=500)
model_rf
```

```{r}
# Stocker le modèle
saveRDS(model_rf, "/Users/natachanjongwayepnga/Documents/GitHub/LeCoinStat/R_Pour_La_Datascience/Jour7/model_randomforest.rds")
```

```{r}
# Importance des variables
varImp(model_rf)
```

```{r}
varImpPlot(model_rf)
```

```{r}
plot(model_rf)
```

```{r}
prediction_train <-  predict(model_rf, type = "prob")[,2]

```

```{r}
prediction_test <- predict(model_rf, newdata = base_test, type = "prob")[,2]

```

```{r}
roc_obj <- roc(base_train$Survived, prediction_train, levels=c("0", "1"))
print(auc(roc_obj))
plot(roc_obj, main="Courbe ROC")
```

```{r}
roc_obj <- roc(base_test$Survived, prediction_test, levels=c("0", "1"))
print(auc(roc_obj))
plot(roc_obj, main="Courbe ROC")
```

## Optimisation des paramètres de la forêt aléatoire

```{r}

# Définition des paramètres de validation croisée
control <- trainControl(method="cv", number=5, search="grid")

# Grid de paramètres à tester
tunegrid <- expand.grid(.mtry=c(1, 2, 3, 4, 5))

# Entraînement du modèle avec validation croisée et recherche des meilleurs hyperparamètres
rf_model <- train(Survived ~ ., data=base_train, method="rf", trControl=control, tuneGrid=tunegrid, ntree=500)
```

```{r}

# Meilleurs paramètres trouvés
print(rf_model$bestTune)
```

```{r}

# Entraînement direct avec randomForest pour accès à l'erreur OOB
rf_model_direct <- randomForest(Survived ~ ., data=base_train, mtry=rf_model$bestTune$mtry, ntree=500)


plot(rf_model_direct)

# Importance des variables
importance <- varImp(rf_model, scale=FALSE)
print(importance)

```

```{r}

# Prédiction sur l'ensemble de test
predictions <- predict(rf_model, newdata=base_test)
```

```{r}

# Calcul de l'AUC et tracé de la courbe ROC
prob_predictions <- predict(rf_model, newdata=base_test, type="prob")
roc_obj <- roc(base_test$Survived, prob_predictions[,2], levels=c("0", "1"))
print(auc(roc_obj))
plot(roc_obj, main="Courbe ROC")

```
